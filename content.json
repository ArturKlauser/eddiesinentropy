{"meta":{"title":"Eddies in Entropy","subtitle":null,"description":"Ephemeral Organization of Perpetual Randomness","author":"Artur Klauser","url":"https://nexus.eddiesinentropy.net","root":"/"},"pages":[],"posts":[{"title":"Raspberry Pi OpenVPN Server for ChromeBooks","slug":"Raspberry-Pi-OpenVPN-Server-for-ChromeBooks","date":"2020-02-04T02:00:00.000Z","updated":"2020-02-03T17:01:07.000Z","comments":true,"path":"2020/02/04/Raspberry-Pi-OpenVPN-Server-for-ChromeBooks/","link":"","permalink":"https://nexus.eddiesinentropy.net/2020/02/04/Raspberry-Pi-OpenVPN-Server-for-ChromeBooks/","excerpt":"How to connect a ChromeBook client to an OpenVPN server running on Raspberry Pi.","text":"How to connect a ChromeBook client to an OpenVPN server running on Raspberry Pi. Running OpenVPN on a Raspberry Pi located on your home network is a great way to securely tunnel into your home network while you’re away, allowing you to connect to all the devices in your home. It also serves to keep your traffic secure while you’re roaming on untrusted public WiFi networks. ChromeBooks are an interesting alternative to more fully fledged laptops when you’re travelling and want to stay connected. This article shows how this OpenVPN setup works with ChromeBooks, which are rather picky when it comes to configuring them as OpenVPN clients. OverviewThere are a considerable number of articles one can find about setting up an OpenVPN server on their home network. There are also many ways how they go about getting it done. Surprisingly though, finding a setup that works for letting you connect with a ChromeBook to your OpenVPN turns out more challenging than expected. In the rest of this article we’ll go through all the steps you need to arrive at a fully functional setup that does work with an Acer C720 ChromeBook. This is one of the earlier ChromeBook models and probably on the more restrictive side when it comes to OpenVPN setups. Of course this OpenVPN setup also works for other clients like PCs, Macs, Android phones and tablets etc. which are a bit more forgiving with respect to the parameters they support. The following steps are necessary: Dynamic DNS: If you want to be able to connect to your home network from the outside, you’ll need a way to find it’s IP address. Most internet service providers, like cable or telephone companies, don’t assign a fixed static IP address to you which you could use. The solution is to associate your Raspberry Pi with a dynamic DNS name and update that with the public IP address of your home internet connection whenever that IP address changes. OpenVPN Setup: Setting up OpenVPN requires picking a number of configuration parameters that are compatible with the OpenVPN server and the set of expected OpenVPN clients. Once the right parameters are picked you’ll have to create a number of encryption keys. We’ll walk you through all that. Router Configuration: To connect to the OpenVPN server on your home network from the outside world you need to make sure that the Router allows the OpenVPN traffic through and direct it to your Raspberry PI. ChromeBook Setup: The last step will be setting up the ChromeBook as an OpenVPN client connected to the OpenVPN server on your Raspberry Pi. Dynamic DNSIn order to access the Raspberry Pi on your home network by name, you need to set up a Dynamic DNS record that associates that name with the IP address that is currently assigned to your home by your internet service provider. On your Raspberry Pi you need to install a Dynamic DNS update agent that maintains this association. We’ll use ddclient for this purpose which is a generic update agent that works with a wide range of Dynamic DNS service providers. If you happen to own a domain name, you can use your domain registrar to set up a Dynamic DNS record under your domain. Different registrars have different interfaces how to do that, so you have to read their documentation to find out. For example, if you’re using Google Registrar for your domain, in its web UI it has an entry for DNS -&gt; Synthetic records that allows you to add entries for Dynamic DNS as a sub-domain in your domain. You could use vpn.&lt;mydomain&gt; as the Dynamic DNS record for your home VPN setup. That UI shows you a Username and Password which you’ll have to copy to your ddclient configuration on the Raspberry Pi. More on that later. If you don’t own a domain name it’s not a problem either. There are a number of Dynamic DNS providers out there with different sets of features and prices. We’ll walk you through using No-IP which offers a free plan for up to 3 Dynamic DNS records. A disadvantage of this free plan is that every 30 days you’ll have to manually confirm that you’re still using it. That’s the price for free. Here is how to set it up: Sign up for a free No-IP account at https://www.noip.com/sign-up Fill in the Email and Password fields. Note that this is also the password that you’ll have to store (in clear text) in your Raspberry Pi ddclient configuration. So I’d advise to use a generated password. Instead of filling in a Hostname, check Create my hostname later. Agree to the terms of service and click Free Sign Up You’ll get sent an email to the address you entered, which contains a link to finish the signup. Wait for that email and click the Confirm Account link in it. On the page that opens, click on My Account on the top menu. Add a User Name and Security Question as requested by the page. This User Name will also need to get stored in the Raspberry Pi ddclient configuration later. This concludes your account setup. Click on Dynamic DNS in the left-hand sidebar menu, then click Create Hostname Fill in the Hostname with a unique name for your VPN and pick a domain from the Free Domains. I’ll pick ddns.net as an example. Set Record Type to DNS Host(A) for an IPv4 address. Your currently assigned IPv4 address should already be filled in, just leave as is. But don’t worry if it’s not, ddclient will fill it in later. Click Create Hostname. If you get an error message that the name is already taken pick a different hostname - it must be unique across all people using this service. You have now set up a Dynamic DNS record on the No-IP site. The next step is to configure an update client that keeps that Dynamic DNS record up to date with the public IP address of your home network. For that, log in to your Raspberry Pi and install ddclient:12sudo apt-get updatesudo apt-get install ddclient Once installed you need to configure it. Make sure the /etc/default/ddclient file contains the following lines:123run_dhclient=&quot;false&quot;run_ipup=&quot;false&quot;run_daemon=&quot;true&quot; If any of those flags are set differently, change them and save the file. Then edit the /etc/ddclient.conf file. It was filled in with some rudimentary settings by the ddclient installation. Overwrite those with the following contents:12345678# no-ip.comprotocol=dyndns2use=web, web=checkip.dyndns.com, web-skip=&apos;IP Address&apos;ssl=yesserver=dynupdate.no-ip.comlogin=&lt;your-noip-username&gt;password=&lt;your-noip-password&gt;&lt;your-noip-hostname&gt;.ddns.net Here &lt;your-noip-username&gt;, &lt;your-noip-password&gt;, and &lt;your-noip-hostname&gt; should be the User Name, Password, and Hostname you have chosen earlier in the account setup on the No-IP web site. If you have your own domain, use the corresponding values from your domain registrar’s Dynamic DNS settings instead. Once this file is saved restart ddclient:12sudo systemctl restart ddclientsudo systemctl status ddclient You should see that ddclient has started successfully. If there were errors it might be helpful to look into the /var/log/syslog file for error messages - search for ddclient. OpenVPN SetupThe next task is to set up the OpenVPN server on your Raspberry Pi. Out of the many options to do this, I’ll describe a simple one that involves a setup script that already does all the work for you, you just have to answer some questions. On your Raspberry Pi first install the setup script12curl -O https://raw.githubusercontent.com/angristan/openvpn-install/master/openvpn-install.shchmod +x openvpn-install.sh and then run it1sudo ./openvpn-install.sh This script will ask you a series of questions and then configure OpenVPN and easy-rsa appropriately. Answer the questions as follows: IP address: it’ll suggest your local IP address which should be fine Public IPv4 address or hostname: set this to &lt;your-noip-hostname&gt;.ddns.net, i.e. the Dynamic DNS name that you have chosen and set up earlier in the /etc/ddclient.conf file. Side note: This is only used for /etc/openvpn/client-template.txt which is the header for generating clients’ *.ovpn files. The *.ovpn file header can be edited later to change things by hand if necessary. Do you want to enable IPv6 support (NAT)?: leave default ‘n’ Port choice : leave default ‘1’, port 1194 Protocol: leave default ‘1’, UDP DNS: I like to pick Google ‘9’, but pick whatever you feel comfortable with Enable compression: leave default ‘n’ Customize encryption settings: pick ‘y’ (not default) This is how we’re going to set up OpenVPN in a way that is compatible with ChromeBook VPN clients. Cipher: pick ‘3’, AES-256-GCM (not default) Certificate Type: pick ‘2’, RSA (not default) The Acer C720 ChromeBook doesn’t support the default setting which uses elliptic curve cryptography. RSA Key Size: leave default ‘1’, 2048 bits Control channel cypher: pick ‘2’ ECDHE-RSA-AES-256-GCM-SHA384 (not default) DH key type: pick ‘2’, DH (not default) The Acer C720 ChromeBook doesn’t support the default setting which uses elliptic curve cryptography. DH key size: leave default ‘1’, 2048 bits Digest algorithm: pick ‘2’, SHA-384 (not default) Control channel additional security mechanism: pick ‘2’, tls-auth (not default) The Acer C720 ChromeBook doesn’t support the default setting with encryption for TLS Press return to let the installation and configuration run. It’ll install all necessary software packages and configures the OpenVPN server according to the answers to the previous questions. Side note: This sets up: /etc/openvpn and inside of that easy-rsa /etc/systemd/system/openvpn@.service, which is a copy of /lib/systemd/system/openvpn@.service with some modifications /etc/iptables: add-openvpn-rules.sh and rm-openvpn-rules.sh /etc/systemd/system/iptables-openvpn.service which starts iptables rules Once done it asks you to set up your first OpenVPN client. We’ll set up the ChromeBook client. Client name: &lt;mychromebook&gt; (pick whatever name you want for your ChromeBook OpenVPN client configuration file) Add passwordless client: leave default ‘1’. For this example we won’t put a password on the OpenVPN client configuration, but you can if you want to. Now the setup process is complete and you should have the shell prompt back. The last part of the setup process, client setup, has created a file &lt;mychromebook&gt;.ovpn in your home directory on the Raspberry Pi. In order to be a bit more organized I like to create a separate directory where I keep all OpenVPN client files:123export MYCHROMEBOOK=&lt;mychromebook&gt;mkdir -p ~/vpnmv ~/$MYCHROMEBOOK.ovpn ~/vpn/ In order to add more clients later just rerun sudo ./openvpn-install.sh and choose the option Add a new user which will ask you for the next client name. If the client configuration is for another type of client instead of a ChromeBook, it is quite likely that it could import the *.ovpn file directly. E.g. the Tunnelblick client for MacOSX or the OpenVPN Connect client for Android can both directly import *.ovpn files to configure the connection to an OpenVPN server. Router ConfigurationThe Raspberry Pi in your home is typically behind some router which is the interface between the outside world and your home network. When you’re out and about, your OpenVPN client machine is on one side of that router whereas your OpenVPN server machine, the Raspberry Pi, is on the other side of that router. What you need to do is go to your router’s configuration page and allow the OpenVPN traffic to pass through. We’ve set up OpenVPN to use UDP port 1194, so find the appropriate router settings, add that port to the allowed traffic, and have the router send it to your Raspberry Pi’s internal IP address on your home network. Since all routers are different I can’t give detailed instructions on how to do that on your router. If you can’t figure it out by yourself, there should be plenty of instructions floating around the internet that show how to do that for your particular router. ChromeBook SetupNow for the last part, setting up the OpenVPN client on the ChromeBook. Unfortunately ChromeBooks can’t import *.ovpn files directly. Also, their GUI for setting up VPN connections is extremely restrictive, not allowing access to most of the settings we need. ChromeBooks do, however, understand a different type of VPN configuration file called *.onc file. But they’re very picky about this file and give you little help figuring out what the problem is if something goes wrong. What we need to do is convert the *.ovpn file to a *.onc file and import that on the ChromeBook. To do that, first download the onc_converter.py:12curl -O https://gist.githubusercontent.com/ArturKlauser/ed5af568ed9ccf9be1c0a1ffb833587d/raw/a33f0ac031d44a4dd0f5a8b168308e1be885045d/onc_converter.pychmod 755 onc_converter.py And then run it on the .ovpn file you generated earlier:1./onc_converter.py --infile vpn/$MYCHROMEBOOK.ovpn --name &quot;user-friendly VPN name&quot; --outfile vpn/$MYCHROMEBOOK.onc The user-friendly VPN name is the name by which the VPN connection will show up on your ChromeBook later. Now copy the vpn/$MYCHROMEBOOK.onc file to your ChromeBook, e.g. via USB stick, and import it: On your ChromeBook, in a new browser window/tab, type: chrome://net-internals/#chromeos In the ‘Import ONC files’ section, click ‘Choose File’. Select your $MYCHROMEBOOK.onc file, e.g. from your USB stick if that is how you are transferring the file. In a new browser window/tab, type: chrome://settings/certificates Click on ‘Authorities’. Find your CA name, which is of the form org-cn_* and click ‘…’ -&gt; ‘Edit’. Check ‘Trust this certificate for identifying websites’ and click OK. In a new browser window/tab, type: chrome://settings/networks?type=VPN Verify that you have a ‘VPN’ entry in the ‘Network’ section with the user-friendly VPN name you set earlier in the .ovpn to .onc conversion process. Attempt to connect. The first time you will be prompted for a password which isn’t actually used for anything (same as the user name) but you must fill in something arbitrary, i.e. you can’t leave it blank. Scroll to the bottom and make sure that Saving identity and password is turned on so the (useless) password is saved and you’re not asked again. That’s it, your ChromeBook should be connected to the OpenVPN server running on the Raspberry Pi in your home network. You can see that by the little key symbol next to the network/wifi symbol. ReferencesThis article is partially based on information found in the following references: Creating an OpenVPN Configuration for ChromeOS OpenVPN on ChromeOS Open Network Configuration openvpn-install How to run your own OpenVPN server on a Raspberry PI","categories":[],"tags":[{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://nexus.eddiesinentropy.net/tags/Raspberry-Pi/"},{"name":"ChromeBook","slug":"ChromeBook","permalink":"https://nexus.eddiesinentropy.net/tags/ChromeBook/"}],"author":"Artur Klauser"},{"title":"Building Multi-Architecture Docker Images With Buildx","slug":"Building-Multi-architecture-Docker-Images-With-Buildx","date":"2020-01-12T09:13:00.000Z","updated":"2020-01-20T08:18:16.000Z","comments":true,"path":"2020/01/12/Building-Multi-architecture-Docker-Images-With-Buildx/","link":"","permalink":"https://nexus.eddiesinentropy.net/2020/01/12/Building-Multi-architecture-Docker-Images-With-Buildx/","excerpt":"How to create your own Docker images that run on multiple CPU architectures.","text":"How to create your own Docker images that run on multiple CPU architectures. With the recent introduction of Docker’s buildx functionality it becomes possible and relatively easy for everybody to build and publish Docker images that work on multiple CPU architectures. This article focuses exclusively on Linux multi-architecture docker images, shows how to go about creating such images, and what to look out for to make it work in different host environments. It’ll cover Ubuntu and Debian distributions in particular, which are used in a number of CI/CD pipelines such as Github Actions or Travis, but it’s generally applicable to other Linux distributions too. You just need to make sure to check which kernel and userspace tool versions you’ve got. The article assumes you’re generally familiar with using Docker. If you don’t know Docker yet, you can familiarize yourself with the basics with Docker’s Getting Started guide. Make sure you get the Hello World example working before continuing here. How Docker Buildx Compiles for Non-Native ArchitecturesDocker buildx multi-architecture support can make use of either native builder nodes running on different architectures or the QEMU processor emulator. We’re only going to discuss QEMU here as it’s a pure software solution that doesn’t require you to have access to hosts that run on different CPU architectures. QEMU works by simulating all instructions of a foreign CPU instruction set on your host processor. E.g. it can simulate ARM CPU instructions on an x86 host machine. With the QEMU simulator in place you can run foreign architecture binaries on your host. But to do so, you’d have to write every command with a prefix qemu-&lt;arch&gt; &lt;your-command&gt; on the command line. Luckily, Linux also has built-in support for running non-native binaries, called binfmt_misc. Whenever Linux tries to execute a binary, it checks if there is a handler for that binary format registered with binfmt_misc. If there is, the handler is executed instead and pointed to the binary. The handler in turn executes the binary however it sees fit. An example of this is executing java byte code binaries with a JVM which interprets each java byte code. In our case we’ll make use of binfmt_misc to transparently execute foreign CPU binaries with QEMU. Software Requirements for Buildx Non-Native Architecture SupportThere are several software requirements that need to be met so docker buildx can create multi-architecture images: Docker &gt;= 19.03: Docker itself needs to be new enough to contain the buildx feature. Experimental mode for the docker CLI needs to be turned on since buildx is an experimental feature. Linux kernel &gt;= 4.8: The kernel side of binfmt_misc needs to be new enough to support the fix-binary (F) flag. The fix-binary flag allows the kernel to use a binary format handler registered with binfmt_misc inside a container or chroot even though that handler binary is not part of the file system visible inside that container or chroot. binfmt_misc file system mounted: The binfmt_misc file system needs to be mounted such that userspace tools can control this kernel feature, i.e. register and enable handlers. Either a Host installation or Docker image based installation of QEMU and binfmt_misc support tools. Host installation: QEMU installed: To execute foreign CPU instructions on the host, QEMU simulators need to be installed. They need to be statically linked since dynamic library resolution depends on those dynamic libraries being visible in the file system at time of use, which is not typically the case inside a container or chroot environment. binfmt-support package &gt;= 2.1.7: You need to install a package that contains an update-binfmts binary new enough to understand the fix-binary (F) flag and actually use it when registering QEMU simulators. Docker image based installation: You can use a Docker image that contains both QEMU binaries and setup scripts that register QEMU in binfmt_misc similar to what the binfmt-support package does. If you happen to run on a system that has Docker Desktop &gt;= 2.1.0 installed, e.g. on Mac OSX or Windows, you’re in luck since it comes configured meeting all the above requirements. In this case you can skip the rest of this section. However, if you’re running on a system where Docker Desktop is not available or installed, e.g. Linux, you’ll have to install the necessary support yourself. The rest of this section assumes you’re running on Linux x86. Now let’s go through these requirements one by one. DockerDocker gained buildx support with version 19.03, so you need at least this version installed. You can check your docker version with:12$ docker --versionDocker version 19.03.5, build 633a0ea838 If you don’t have docker installed on your system you can try to install it from your Linux distribution’s default package sources. The package typically comes by the name of docker-ce or docker.io (see also the table of popular Linux environments below):12345678910111213141516$ sudo apt-get install -y docker-ceReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following NEW packages will be installed: docker-ce0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.Need to get 0 B/22.8 MB of archives.After this operation, 109 MB of additional disk space will be used.Selecting previously unselected package docker-ce.(Reading database ... 120478 files and directories currently installed.)Preparing to unpack .../docker-ce_5%3a19.03.5~3-0~ubuntu-bionic_amd64.deb ..Unpacking docker-ce (5:19.03.5~3-0~ubuntu-bionic) ...Setting up docker-ce (5:19.03.5~3-0~ubuntu-bionic) ...Processing triggers for systemd (237-3ubuntu10.33) ...Processing triggers for ureadahead (0.100.0-21) ... It’s quite possible though that the docker version that comes by default with your Linux distribution is not new enough. In that case you can add Docker’s own package repository and get a newer docker version from there:123456DOCKER_APT_REPO='https://download.docker.com/linux/ubuntu'curl -fsSL \"$&#123;DOCKER_APT_REPO&#125;/gpg\" | sudo apt-key add -OS=\"$(lsb_release -cs)\"sudo add-apt-repository \"deb [arch=amd64] $DOCKER_APT_REPO $OS stable\"sudo apt-get updatesudo apt-get -y -o Dpkg::Options::=\"--force-confnew\" install docker-ce Docker Experimental FeaturesAs of this writing (early 2020), buildx is an experimental feature. If you try to use it without turning on experimental features it’ll fail:123$ docker buildxdocker: 'buildx' is not a docker command.See 'docker --help' You can turn on experimental Docker CLI features in one of two ways. Either by setting an environment variable1$ export DOCKER_CLI_EXPERIMENTAL=enabled or by turning the feature on in the config file:$HOME/.docker/config.json1234&#123; ... \"experimental\" : \"enabled\"&#125;If you choose the environment variable, put the setting into you shell startup script, e.g. $HOME/.bashrc for bash, otherwise the setting only sticks around in your current shell until you log out. Once you have turned on experimental features either way, you can check that it has taken effect with:12345$ docker versionClient: Docker Engine - Community ... Experimental: true ... Note that this output also shows you the status of the Experimental flag of Server: Docker Engine. But this doesn’t concern us for now. With experimental mode now turned on, you should have access to the docker buildx command:123456789101112131415161718192021$ docker buildxUsage: docker buildx COMMANDBuild with BuildKitManagement Commands: imagetools Commands to work on images in registryCommands: bake Build from a file build Start a build create Create a new builder instance inspect Inspect current builder instance ls List builder instances rm Remove a builder instance stop Stop builder instance use Set the current builder instance version Show buildx version informationRun 'docker buildx COMMAND --help' for more information on a command. Linux KernelYou need a kernel that supports the binfmt_misc feature and has it enabled. In particular, the binfmt_misc support needed to use QEMU transparently inside containers is the fix-binary (F) flag which requires a Linux kernel version &gt;= 4.8 (commit, commit). You can check your kernel version with:12$ uname -r4.15.0 Binfmt_misc File SystemThe binfmt_misc kernel features are controlled via files in /proc/sys/fs/binfmt_misc/. This file system must be mounted. E.g. on a Ubuntu 18.04 (bionic) system the script responsible for mounting that file system is /lib/systemd/system/proc-sys-fs-binfmt_misc.automount which is part of the systemd package and runs automatically at boot time (and also during package installation). You can check if the file system is mounted with:12$ ls /proc/sys/fs/binfmt_misc/register status Host Installation: QEMUAn easy way to install statically linked QEMU binaries is to use a pre-built package for your host Linux distribution. E.g. for Debian or Ubuntu you can install it with:1234567891011121314151617181920212223242526$ sudo apt-get install -y qemu-user-staticReading package lists... DoneBuilding dependency treeReading state information... DoneThe following additional packages will be installed: binfmt-supportThe following NEW packages will be installed: binfmt-support qemu-user-static0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.Need to get 10.1 MB of archives.After this operation, 101 MB of additional disk space will be used.Get:1 http://us-east-2.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 binfmt-support amd64 2.1.8-2 [51.6 kB]Get:2 http://us-east-2.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 qemu-user-static amd64 1:2.11+dfsg-1ubuntu7.21 [10.0 MB]Fetched 10.1 MB in 0s (22.0 MB/s)Selecting previously unselected package binfmt-support.(Reading database ... 120409 files and directories currently installed.)Preparing to unpack .../binfmt-support_2.1.8-2_amd64.deb ...Unpacking binfmt-support (2.1.8-2) ...Selecting previously unselected package qemu-user-static.Preparing to unpack .../qemu-user-static_1%3a2.11+dfsg-1ubuntu7.21_amd64.deb ...Unpacking qemu-user-static (1:2.11+dfsg-1ubuntu7.21) ...Setting up binfmt-support (2.1.8-2) ...Setting up qemu-user-static (1:2.11+dfsg-1ubuntu7.21) ...Processing triggers for ureadahead (0.100.0-21) ...Processing triggers for systemd (237-3ubuntu10.33) ...Processing triggers for man-db (2.8.3-2ubuntu0.1) ... That has installed QEMU for a number of foreign architectures, e.g. 64-bit ARM (aarch64), as you can see by checking:123456$ ls -l /usr/bin/qemu-aarch64-static-rwxr-xr-x 1 root root 3621200 Oct 15 09:23 /usr/bin/qemu-aarch64-static$ qemu-aarch64-static --versionqemu-aarch64 version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.21)Copyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers Other Linux distributions might use different package managers or package names for the QEMU package. Alternatively you can install QEMU from source and follow the build instructions. Host Installation: update-binfmts ToolThe update-binfmts tool is typically part of the binfmt-support package. If you look back at the installation of qemu-user-static above you’ll see that it has automatically pulled in the recommended binfmt-support package, so in our case it’s already installed. But if you’ve specified the --no-install-recommends flag (or that is set by default on your system), binfmt-support might not yet be installed. If it’s missing on your system you can also install it manually with:1234567$ sudo apt-get install -y binfmt-supportReading package lists... DoneBuilding dependency treeReading state information... Donebinfmt-support is already the newest version (2.1.8-2).binfmt-support set to manually installed.0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. Here again, we need support for the fix-binary (F) flag, which was added to update-binfmts with version 2.1.7. You can check the version with:12$ update-binfmts --versionbinfmt-support 2.1.8 Checking Your Host SystemPutting everything together, you can check if the aforementioned environment is in place for using QEMU with docker buildx with the following check-qemu-binfmt.sh script: Problem: QEMU Not Registered With (F) FlagIn some environments you can run into the situation that the appropriate kernel and update-binfmts support is present, but the qemu-user-static post-install script does not register QEMU with the fix-binary (F) flag. The checker script above will point that out. One such environment is e.g. AWS EC2 instances running Ubuntu 18.04 (bionic). In such a case you can fix up the installation by re-registering QEMU with the fix-binary (F) flag with the following reregister-qemu-binfmt.sh script: Docker Image Based InstallationAs an alternative to installing the QEMU and binfmt-support packages on your host system you can use a docker image to satisfy the corresponding requirements. There are several docker images that do the job, among them multiarch/qemu-user-static and docker/binfmt. They come loaded with QEMU simulators for several architectures and their own setup script for installing those QEMU simulators in the host kernel’s binfmt_misc with the fix-binary (F) flag. The QEMU simulators stay registered and usable by the host kernel after running that docker image as long as the host system remains up (or you explicitly unregister them from binfmt_misc). That is what also makes them usable by later runs of docker buildx. Unlike the host installation of packages though, you’ll need to re-run that docker image after every system reboot. Using those images doesn’t release you from having the right docker and kernel version on the host system, but you do get around installing QEMU and binfmt-support packages on the host. I like to use multiarch/qemu-user-static:1234567891011121314$ docker run --rm --privileged multiarch/qemu-user-static --reset -p yesUnable to find image 'multiarch/qemu-user-static:latest' locallylatest: Pulling from multiarch/qemu-user-staticbdbbaa22dec6: Pull complete42399a41a764: Pull completeed8a5179ae11: Pull complete1ec39da9c97d: Pull completedf7dd9470aac: Pull completeDigest: sha256:25d6e8bb037094525cd70da43edc06a62122028cb9ad434605affbd4fffb3a4fStatus: Downloaded newer image for multiarch/qemu-user-static:latestSetting /usr/bin/qemu-alpha-static as binfmt interpreter for alphaSetting /usr/bin/qemu-arm-static as binfmt interpreter for armSetting /usr/bin/qemu-armeb-static as binfmt interpreter for armeb... Status of Popular Linux EnvironmentsThe following table shows the current status of docker buildx support on various popular Linux environments. Only Ubuntu &gt;= 19.10 (eoan) and Debian 11 (bullseye/testing) come with sufficient support by default to be able to run docker buildx out of the box. All older versions of these Linux distributions need updates of various components in order to be compatible with docker buildx usage. For example Ubuntu 18.04 (bionic) requires re-registration of QEMU with the fix-binary (F) flag or usage of the docker image installation method for QEMU as described above as well as an upgraded docker package. Environment Docker Package Kernel binfmt-support (F) Flag Requirements &gt;= 19.03 &gt;= 4.8 &gt;= 2.1.7 yes Ubuntu: 18.04 (bionic) 17.12.1 docker.io 4.15.0 2.1.8 no 19.04 (disco) 18.09.5 docker.io 5.0 2.2.0 yes 19.10 (eoan) 19.03.2 docker.io 5.3 2.2.0 yes 20.04 (focal) 19.03.2 docker.io 5.5 2.2.0 yes Debian: 9 (stretch) - 4.9.0 2.1.6 no 10 (buster) 18.09.1 docker.io 4.19.0 2.2.0 yes 11 (bullseye/testing) 19.03.4 docker.io 5.4 2.2.0 yes AWS EC2: Ubuntu 16.04 (xenial) 18.09.7 docker.io 4.4.0 2.1.6 no Ubuntu 18.04 (bionic) 18.09.7 docker.io 4.15.0 2.1.8 no Travis (on GCP): Ubuntu 14.04 (trusty) 17.09.0 docker-ce 4.4.0 2.1.4 no Ubuntu 16.04 (xenial) 18.06.0 docker-ce 4.15.0 2.1.6 no Ubuntu 18.04 (bionic) 18.06.0 docker-ce 4.15.0 2.1.8 no Github Actions (on Azure): Ubuntu 16.04 (xenial) 3.0.8 moby-engine 4.15.0 2.1.6 no Ubuntu 18.04 (bionic) 3.0.8 moby-engine 5.0.0 2.1.8 no Building Multi-Architecture Docker Images With BuildxWith all the software requirements on the host met, it’s time to turn our attention to how buildx is used to create multi-architecture docker images. The first step is setting up a buildx builder. Creating a Buildx BuilderThe docker CLI now understands the buildx command, but you also need to create a new builder instance which buildx can use:123$ docker buildx create --name mybuildermybuilder$ docker buildx use mybuilder You can check your newly created mybuilder with:1234567891011121314$ docker buildx inspect --bootstrap[+] Building 3.5s (1/1) FINISHED =&gt; [internal] booting buildkit 3.5s =&gt; =&gt; pulling image moby/buildkit:buildx-stable-1 2.9s =&gt; =&gt; creating container buildx_buildkit_mybuilder0 0.6sName: mybuilderDriver: docker-containerNodes:Name: mybuilder0Endpoint: unix:///var/run/docker.sockStatus: runningPlatforms: linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le,linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 Note how the Platforms line reports support for various non-native architectures which you have installed via QEMU. If it only reports support for linux/amd64 and linux/386 you either still haven’t met all software requirements, or you had created a builder before you have met the software requirements. In the latter case remove it with docker buildx rm and recreate it. You can also see your just created mybuilder with buildx’ ls subcommand:123456$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder * docker-container mybuilder0 unix:///var/run/docker.sock running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 Using Buildx to BuildAlright, now we’re ready to build multi-architecture docker images with buildx. To have something concrete to work with we’re going to use the following example:Dockerfile12FROM alpine:latestCMD echo \"Running on $(uname -m)\" It’s a simple stand-in for whatever you’d like to build yourself in your own Dockerfile. It uses the latest Alpine distribution - which itself is a multi-architecture docker image - and prints out the architecture on which it is executing. That will allow us to check which kind of image we’re running. The docker buildx build subcommand has a number of flags which determine where the final image will be stored. By default, i.e. if none of the flags are specified, the resulting image will remain captive in docker’s internal build cache. This is unlike the regular docker build command which stores the resulting image in the local docker images list. The important flags are: --load: This flag instructs docker to load the resulting image into the local docker images list. However, this currently only works for single-architecture images. If you try this with multi-architecture images you’ll get an export error:$ docker buildx build ... --load ...... =&gt; ERROR exporting to oci image format 0.0s------ &gt; exporting to oci image format:------failed to solve: rpc error: code = Unknown desc = docker exporter does not currently support exporting manifest lists --push: This flag tells docker to push the resulting image to a docker registry. Your image tag has to contain the proper reference to the registry and repository name. This currently is the best way to store multi-architecture images. We’re going to use the default Docker Hub registry. First we have to log in:12345678$ export DOCKER_USER='arturklauser'$ docker login -u \"$DOCKER_USER\"Password: *****WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded Now we can build and use the --push flag to push the image to Docker Hub. In our example we’re going to build for three different architectures - x86, ARM, and PowerPC - which are specified with the --platform flag:123456789101112131415161718192021222324252627$ docker buildx build -t \"$&#123;DOCKER_USER&#125;/buildx-test:latest\" \\ --platform linux/amd64,linux/arm64,linux/ppc64le --push .[+] Building 1.5s (9/9) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 91B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [linux/ppc64le internal] load metadata for docker.io/library/alpin 0.1s =&gt; [linux/amd64 internal] load metadata for docker.io/library/alpine: 0.2s =&gt; [linux/arm64 internal] load metadata for docker.io/library/alpine: 0.2s =&gt; CACHED [linux/ppc64le 1/1] FROM docker.io/library/alpine:latest@sh 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679 0.0s =&gt; CACHED [linux/amd64 1/1] FROM docker.io/library/alpine:latest@sha2 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679 0.0s =&gt; CACHED [linux/arm64 1/1] FROM docker.io/library/alpine:latest@sha2 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679 0.0s =&gt; exporting to image 1.2s =&gt; =&gt; exporting layers 0.0s =&gt; =&gt; exporting manifest sha256:cc57b693aba3acedeec2e624b55e543919173 0.0s =&gt; =&gt; exporting config sha256:d90689831fec93dd68f90509031907cc262f89e 0.0s =&gt; =&gt; exporting manifest sha256:7997da18dbf6e4b2748736821ec6f1dd11d6e 0.0s =&gt; =&gt; exporting config sha256:c105b7a88a6002ad96802aa287be3872d86608a 0.0s =&gt; =&gt; exporting manifest sha256:6ed2267dc7082fbfc4454805b94326418ad14 0.0s =&gt; =&gt; exporting config sha256:5df18a6f10cc8591839d1b29732d3d202edf3c0 0.0s =&gt; =&gt; exporting manifest list sha256:57ca2d778839da0b6287bcbc99fc2299 0.0s =&gt; =&gt; pushing layers 0.2s =&gt; =&gt; pushing manifest for docker.io/arturklauser/buildx-test:latest 0.7s We can check the image with the imagetools subcommand which confirms that three architecture versions are included in the image:1234567891011121314151617$ docker buildx imagetools inspect \"$DOCKER_USER/buildx-test:latest\"Name: docker.io/arturklauser/buildx-test:latestMediaType: application/vnd.docker.distribution.manifest.list.v2+jsonDigest: sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5Manifests: Name: docker.io/arturklauser/buildx-test:latest@sha256:cc57b693aba3acedeec2e624b55e543919173a3e9ed76c2af2f2cd9713b84b78 MediaType: application/vnd.docker.distribution.manifest.v2+json Platform: linux/amd64 Name: docker.io/arturklauser/buildx-test:latest@sha256:7997da18dbf6e4b2748736821ec6f1dd11d6e8493f068fb23913507a9a271e2c MediaType: application/vnd.docker.distribution.manifest.v2+json Platform: linux/arm64 Name: docker.io/arturklauser/buildx-test:latest@sha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899c MediaType: application/vnd.docker.distribution.manifest.v2+json Platform: linux/ppc64le Also, on the Docker Hub web site we see it reported as: To verify that you’ve actually got what you’ve been promised, let’s try to run the image:123456$ docker run --rm \"$DOCKER_USER/buildx-test:latest\"Unable to find image 'arturklauser/buildx-test:latest' locallylatest: Pulling from arturklauser/buildx-testDigest: sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5Status: Downloaded newer image for arturklauser/buildx-test:latestRunning on x86_64 As expected, since we’re running on a 64-bit x86 host, the default architecture version that was used by docker was the amd64 which reports running on x86_64. If you check the local image in docker it confirms that:12$ docker inspect --format \"&#123;&#123;.Architecture&#125;&#125;\" \"$DOCKER_USER/buildx-test:latest\"amd64 To pull and run a specific architecture version, use the image name including its full sha256 value that was reported by imagetools:1234567$ docker run --rm \"$DOCKER_USER/buildx-test:latest@sha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899c\"Unable to find image 'arturklauser/buildx-test:latest@sha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899c' locallysha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899c: Pulling from arturklauser/buildx-testa5dee701e1e8: Pull complete Digest: sha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899cStatus: Downloaded newer image for arturklauser/buildx-test@sha256:6ed2267dc7082fbfc4454805b94326418ad14c530879a7c9d6f02f0961e2899cRunning on ppc64le Since the sha256 value we requested here was that of the PowerPC image version, we see that the image is reporting to run on ppc64le as expected. Optionally, we can pull and run non-native image versions by platform name. For that though we need to turn on another experimental feature, this time in the docker engine, that’ll allow us to specify a --platform. If docker engine experimental features are not turned on you’ll get an error instead: “–platform” is only supported on a Docker daemon with experimental features enabled Change the docker engine configuration file or create one if it doesn’t exist already:/etc/docker/daemon.json1234&#123; ... \"experimental\" : true&#125;After changing the configuration file you’ll also need to restart dockerd for the change to take effect:1$ sudo systemctl restart docker Let’s purge the image that we’ve already pulled and try a different architecture:1234567891011$ docker rmi \"$DOCKER_USER/buildx-test:latest\"Untagged: arturklauser/buildx-test:latestUntagged: arturklauser/buildx-test@sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5$ docker run --rm --platform linux/aarch64 \"$DOCKER_USER/buildx-test:latest\"Unable to find image 'arturklauser/buildx-test:latest' locallylatest: Pulling from arturklauser/buildx-testcde5963f3b93: Pull complete Digest: sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5Status: Downloaded newer image for arturklauser/buildx-test:latestRunning on aarch64 Now we see that the architecture version of the image we’ve pulled and run is the one for 64-bit ARM aarch64, as can also be verified by looking at the image metadata:12$ docker inspect --format \"&#123;&#123;.Architecture&#125;&#125;\" \"$DOCKER_USER/buildx-test:latest\"arm64 With this you’ve got to the point where you can start to build your own multi-architecture docker images with buildx. Happy developing! AppendixThe following script shows how you can use what was described above to build multi-architecture docker images in CI/CD pipelines like Github Actions or Travis.","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://nexus.eddiesinentropy.net/tags/Docker/"}],"author":"Artur Klauser"},{"title":"Mounting Google Drive on Raspberry Pi","slug":"Mounting-Google-Drive-on-Raspberry-Pi","date":"2019-04-21T16:22:00.000Z","updated":"2019-05-21T10:43:45.000Z","comments":true,"path":"2019/04/21/Mounting-Google-Drive-on-Raspberry-Pi/","link":"","permalink":"https://nexus.eddiesinentropy.net/2019/04/21/Mounting-Google-Drive-on-Raspberry-Pi/","excerpt":"How to use rclone, FUSE, and systemd to automatically mount your Google Drive on your Raspberry Pi.","text":"How to use rclone, FUSE, and systemd to automatically mount your Google Drive on your Raspberry Pi. The Raspberry Pi is a great little device to run a variety of services in your home network. It saves files on a user-provided SD card or USB stick. But what if you want to store files off-device to safeguard the work that you’ve put in to set up whatever services you’re running on your Pi? What if you would like to share files between multiple Pis? Or what if you have files like your photos living in the cloud already and you’d like to easily access them from your Pi? This article shows how you can connect your Google Drive to your Raspberry Pi for all the above use cases and more. Which Software to Use?The first thing we have to decide is which software to use. When you look around for software to connect Google Drive to a Linux environment you run into projects with a wide range of different features and requirements. Some are better maintained than others. The one I’ve chosen here is rclone, which is actively maintained and provides a lot of functionality. In particular, with the help of the FUSE userspace filesystem layer, it allows you to mount Google Drive as part of your Linux file system, which greatly simplifies using the cloud storage from your Pi. These instructions will probably also work on most other Debian Linux based distributions with little or no change. Rclone is much more versatile that the limited usage described in this article. It doesn’t only support Google Drive but a whole host of other cloud storage providers as well, such as Amazon Drive, Dropbox, or Microsoft OneDrive to name just a few of the larger ones. Besides allowing you to mount one of those cloud storage services into your file system, it also provides a set of CLI commands to directly manipulate files on those services. In this article, however, we won’t use them and concentrate on using rclone mount. The installation instructions below assume that you’re logged in to your Raspberry Pi and execute all instructions there, unless otherwise noted. Installing Rclone on RaspbianThe easiest way to install rclone is to use the pre-compiled Debian package:1sudo apt-get install rclone As of this writing, the current release of Raspbian is based on Debian v.9 (Stretch), and the version of rclone we get via apt-get is 1.35. However, rclone has progressed to version 1.47 in the meantime. To get a more up-to-date version, instead of using the apt package that comes with the default Raspbian package repositories, we’re going to install an up-to-date rclone package from its download page:1234cd /tmpwget https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-arm.debsudo apt install ./rclone-v1.47.0-linux-arm.debrm rclone-v1.47.0-linux-arm.deb Configuring RcloneSince the remote files we’re going to access are private to a particular user, rclone keeps configuration files separate per user. All secret access tokens necessary to interact with the cloud storage are stored in a user’s config file such that different users can’t access each other’s cloud storage. By default the config file is located in $HOME/.config/rclone/rclone.conf and should have permissions of 0600 (read-write only for file owner) to make sure your access tokens remain private. For Google Drive there is another consideration. If you go with the default configuration, you’re using the client_id that corresponds to the rclone application. Google imposes per-client rate limits on interactions with Google Drive. This means that by using the rclone default client_id you’re competing against all other users of rclone, globally, for operation bandwidth to Google Drive. Even though the rclone authors try to mitigate this by asking Google for higher quotas, using the default is not an ideal situation. For this reason we’ll set up our own client_id with Google and avoid the stampede. Getting a Google Drive Client IDIn a browser go to the Google Developer Console and log in with your Google account. You don’t have to do this on your Raspberry Pi. Any computer is fine. On the top go to Select a project → New Project Fill in a Project Name: my-rclone-gdrive-access Hit Create Just below the top select + ENABLE APIS AND SERVICES Search for Drive Select Google Drive API Hit Enable On the left side-panel select Credentials In the main panel you’ll get a warning about Remember to configure the OAuth consent screen with information about your application. Next to the warning select CONFIGURE CONSENT SCREEN Fill in the Application Name: my-rclone Hit Add Scope Pick ../auth/drive (which can “see, edit, create, and delete all of your Google Drive files”) and hit Add Hit Save Go back to Credentials on the left side-panel and then Credentials on the top menu inside the main panel Select Create credentials → OAuth client ID Select Application type: Other and set some sensible name: my rclone client Hit Create You’ll get a confirmation page containing the client ID and client secret which looks like this. Copy the client ID and client secret since we’ll need it for the rclone configuration. Setting up the Rclone ConfigurationBack on the Raspberry Pi log in as the user who should be able to access the Google Drive files and run:1rclone config Select the following answers: No remotes found - make a new one n) New remote s) Set configuration password q) Quit config n/s/q> n name> gdrive Type of storage to configure. Enter a string value. Press Enter for the default (\"\"). Choose a number from below, or type in your own value ... snip ... 12 / Google Drive \\ \"drive\" ... snip ... Storage> 12 See help for drive backend at https://rclone.org/drive/ Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default (\"\"). client_id> 425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com This is the client ID that you saved in the previous step. Google Application Client Secret Setting your own is recommended. Enter a string value. Press Enter for the default (\"\"). client_secret> MspFTowlsy0SUSRm-1RvcTyx This is the client secret that you saved in the previous step. Scope that rclone should use when requesting access from drive. Enter a string value. Press Enter for the default (\"\"). Choose a number from below, or type in your own value 1 / Full access all files, excluding Application Data Folder. \\ \"drive\" ... snip ... scope> 1 ID of the root folder Leave blank normally. Fill in to access \"Computers\" folders. (see docs). Enter a string value. Press Enter for the default (\"\"). root_folder_id> Service Account Credentials JSON file path Leave blank normally. Needed only if you want use SA instead of interactive login. Enter a string value. Press Enter for the default (\"\"). service_account_file> Edit advanced config? (y/n) y) Yes n) No y/n> n Remote config Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y) Yes n) No y/n> n If your browser doesn't open automatically go to the following link: https://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=18109698827ea077947354ca9dab0b80 Log in and authorize rclone for access Copy the URL that gets printed on your screen to a new browser window. You can do this on any computer, it doesn’t have to be your Pi. In the page flow that follows select your user account (if required) and confirm that you want to give your application access to your Google Drive. Copy the verification code from the confirmation page and fill it in below. Enter verification code> 4/PzWg7ZOEvXIoa9tI7OMjerPq_X5UpsES5ayNvtG8Gf9TK30FERTVrCM Configure this as a team drive? y) Yes n) No y/n> n -------------------- [gdrive] type = drive client_id = 425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com client_secret = MspFTowlsy0SUSRm-1RvcTyx scope = drive token = {\"access_token\":\"xa14.Gv7qcPS5TvrumTpNplGxg5Ndct1gd6yica0d80iFjbKXJ3KpgneZLvn-Tg-YgLPXcEesHubbBcyyeEjGGb9mP5GhwLnEDxaPhPS3fj6ddTcmMUUOdjOhYW-rb1xY\",\"token_type\":\"Bearer\",\"refresh_token\":\"1/8jxfWbRseQmqrb5aebwK9zfwZRH0IjZhv-9lmtqsVC8\", \"expiry\":\"2020-01-23T16:21:03.502362868-07:00\"} -------------------- This last section shown above is a copy of the information that will be put into the $HOME/.config/rclone/rclone.conf config file. If everything looks correct we’re going to accept it and exit the configuration menu. y) Yes this is OK e) Edit this remote d) Delete this remote y/e/d> y Current remotes: Name Type ==== ==== gdrive drive e) Edit existing remote n) New remote d) Delete remote r) Rename remote c) Copy remote s) Set configuration password q) Quit config e/n/d/r/c/s/q> q You can now test that you have set up the configuration correctly with:1rclone ls --max-depth 1 gdrive: This rclone command should show you all regular files in the top-level directory of your Google Drive. The next step is to test mounting Google Drive into your file system:123cd ~mkdir -p mnt/gdriverclone mount gdrive: $HOME/mnt/gdrive In a second terminal on your Raspberry Pi run:1ls -l ~/mnt/gdrive This should again list all files in the top-level directory of your Google Drive. Since your cloud storage is now part of the regular file system, any program on you Pi can access it just like any other file. After this test stop the above rclone command in the first terminal with Ctrl-C. Automatically Mounting Google DriveThe setup above is all that is necessary to use the rclone mount command and mount Google Drive by hand into your file system whenever you need it. However, that is a bit cumbersome. It would be better if Google drive were mounted automatically whenever the corresponding user logs in. This can be achieved with systemd, a daemon that starts and stops services when needed. Systemd operates in one of two modes, a –system mode that handles machine-wide services such as bringing up networking, and a –user mode that deals with per-user services such as starting the desktop environment and in our case we want it to mount the rclone FUSE file system for Google Drive. A good place to learn more is the archlinux wiki for per-user systemd. Configuring SystemdTo tell systemd what to do it depends on configuration files in some standard locations. One of these locations where systemd looks for user config files is $HOME/.config/systemd/user. To have the rclone FUSE file system mounted automatically at login we’ll create a ~/.config/systemd/user/rclone@.service file with the following contents:12345678910111213141516[Unit]Description=rclone: Remote FUSE filesystem for cloud storage config %iDocumentation=man:rclone(1)[Service]Type=notifyExecStartPre=/bin/mkdir -p %h/mnt/%iExecStart= \\ /usr/bin/rclone mount \\ --fast-list \\ --vfs-cache-mode writes \\ --vfs-cache-max-size 100M \\ %i: %h/mnt/%i[Install]WantedBy=default.target Here the special @ syntax in the config filename defines a service template which allows to write a single config file that can be used for multiple instantiations. Even though we wouldn’t really need a service template for our simple use case, we use it so the configuration already supports multiple mounts, e.g. if you also want to use it for other cloud storage providers as well. When using the systemd service name, which derives from the file name, you just append an instance name to @ and systemd will replace all occurrences of %i in the config file with that instance name. In our case the instance name represents the rclone remote name which we have configured in the rclone.conf file above, i.e. gdrive in our case. On the rclone mount command line above we use a particular set of mount options that are supported for Google Drive. A full list of options can be found in the rclone Google Drive documentation. More details on general mount options can be found in the rclone mount documentation. Once we’ve got the config file in place we need to let systemd know about the new configuration for our gdrive rclone remote:1systemctl --user enable rclone@gdrive This should install a symbolic link rclone@gdrive.service -&gt; $HOME/.config/systemd/user/rclone@.service in ~/.config/systemd/user/default.target.wants/. Now that systemd is aware of the new service, the next step is to turn it on:1systemctl --user start rclone@gdrive Once turned on, when you list the mount directory1ls -l ~/mnt/gdrive you should see the contents of your Google Drive directory again. At this point what we have achieved works great for interactive user sessions. Every time you log in to your Raspberry Pi as the user for which you have set up Google Drive, it is mounted automatically into the file system which gives you access to the contents of your cloud storage. Starting User-Systemd at Boot TimeFor some use cases, mounting at user login time is still not quite enough. For example on my system I run an RStudio Server, which is a web IDE for the R programming language. The RStudio Server web interface first presents a login page to authenticate the user. Once it has checked the user’s credentials it starts an rsession for them. However, starting an rsession with the UID of the authenticated user doesn’t constitute a login or session for that user. Thus no systemd user session is started and the actions that would mount the cloud storage are not performed, so the RStudio IDE doesn’t have access to the cloud storage directory of the user. There is a solution to this problem though. We can instruct systemd to start a user session at boot time instead of login time with the following command:1loginctl enable-linger $USER Now, whenever our Raspberry Pi reboots, a systemd user session is started immediately for that user, mounting the configured Google Drive and enabling use cases like RStudio Server mentioned above. If you’ve followed the setup to here, congratulations! You’ve got your Raspberry Pi connected to your Google Drive and can easily access files from your cloud storage from any program running on your Pi just by accessing files under $HOME/mnt/gdrive.","categories":[],"tags":[{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://nexus.eddiesinentropy.net/tags/Raspberry-Pi/"}],"author":"Artur Klauser"}]}