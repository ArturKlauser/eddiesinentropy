{"meta":{"title":"Eddies in Entropy","subtitle":null,"description":"Ephemeral Organization of Perpetual Randomness","author":"Artur Klauser","url":"https://nexus.eddiesinentropy.net","root":"/"},"pages":[],"posts":[{"title":"Building Multi-Architecture Docker Images With Buildx","slug":"Building-Multi-architecture-Docker-Images-With-Buildx","date":"2020-01-12T09:13:00.000Z","updated":"2020-01-17T16:36:09.000Z","comments":true,"path":"2020/01/12/Building-Multi-architecture-Docker-Images-With-Buildx/","link":"","permalink":"https://nexus.eddiesinentropy.net/2020/01/12/Building-Multi-architecture-Docker-Images-With-Buildx/","excerpt":"How to create your own Docker images that run on multiple CPU architectures.","text":"How to create your own Docker images that run on multiple CPU architectures. With the recent introduction of Docker’s buildx functionality it becomes possible and relatively easy for everybody to build and publish Docker images that work on multiple CPU architectures. This article focuses exclusively on Linux multi-architecture docker images, shows how to go about creating such images, and what to look out for to make it work in different host environments. It’ll cover Ubuntu and Debian distributions in particular, which are used in a number of CI/CD pipelines such as Github Actions or Travis, but it’s generally applicable to other Linux distributions too. You just need to make sure to check which kernel and userspace tool versions you’ve got. The article assumes you’re generally familiar with using Docker. If you don’t know Docker yet, you can familiarize yourself with the basics with Docker’s Getting Started guide. Make sure you get the Hello World example working before continuing here. How Docker Buildx Compiles for Non-Native ArchitecturesDocker buildx multi-architecture support can make use of either native builder nodes running on different architectures or the QEMU processor emulator. We’re only going to discuss QEMU here as it’s a pure software solution that doesn’t require you to have access to hosts that run on different CPU architectures. QEMU works by simulating all instructions of a foreign CPU instruction set on your host processor. E.g. it can simulate ARM CPU instructions on an x86 host machine. With the QEMU simulator in place you can run foreign architecture binaries on your host. But to do so, you’d have to write every command with a prefix qemu-&lt;arch&gt; &lt;your-command&gt; on the command line. Luckily, Linux also has built-in support for running non-native binaries, called binfmt_misc. Whenever Linux tries to execute a binary, it checks if there is a handler for that binary format registered with binfmt_misc. If there is, the handler is executed instead and pointed to the binary. The handler in turn executes the binary however it sees fit. An example of this is executing java byte code binaries with a JVM which interprets each java byte code. In our case we’ll make use of binfmt_misc to transparently execute foreign CPU binaries with QEMU. Software Requirements for Buildx Non-Native Architecture SupportThere are several software requirements that need to be met so docker buildx can create multi-architecture images: Docker &gt;= 19.03: Docker itself needs to be new enough to contain the buildx feature. Experimental mode for the docker CLI needs to be turned on since buildx is an experimental feature. Linux kernel &gt;= 4.8: The kernel side of binfmt_misc needs to be new enough to support the fix-binary (F) flag. The fix-binary flag allows the kernel to use a binary format handler registered with binfmt_misc inside a container or chroot even though that handler binary is not part of the file system visible inside that container or chroot. binfmt_misc file system mounted: The binfmt_misc file system needs to be mounted such that userspace tools can control this kernel feature, i.e. register and enable handlers. Either a Host installation or Docker image based installation of QEMU and binfmt_misc support tools. Host installation: QEMU installed: To execute foreign CPU instructions on the host, QEMU simulators need to be installed. They need to be statically linked since dynamic library resolution depends on those dynamic libraries being visible in the file system at time of use, which is not typically the case inside a container or chroot environment. binfmt-support package &gt;= 2.1.7: You need to install a package that contains an update-binfmts binary new enough to understand the fix-binary (F) flag and actually use it when registering QEMU simulators. Docker image based installation: You can use a Docker image that contains both QEMU binaries and setup scripts that register QEMU in binfmt_misc similar to what the binfmt-support package does. If you happen to run on a system that has Docker Desktop &gt;= 2.1.0 installed, e.g. on Mac OSX or Windows, you’re in luck since it comes configured meeting all the above requirements. In this case you can skip the rest of this section. However, if you’re running on a system where Docker Desktop is not available or installed, e.g. Linux, you’ll have to install the necessary support yourself. The rest of this section assumes you’re running on Linux x86. Now let’s go through these requirements one by one. DockerDocker gained buildx support with version 19.03, so you need at least this version installed. You can check your docker version with:12$ docker --versionDocker version 19.03.5, build 633a0ea838 If you don’t have docker installed on your system you can try to install it from your Linux distribution’s default package sources. The package typically comes by the name of docker-ce or docker.io (see also the table of popular Linux environments below):12345678910111213141516$ sudo apt-get install -y docker-ceReading package lists... DoneBuilding dependency tree Reading state information... DoneThe following NEW packages will be installed: docker-ce0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.Need to get 0 B/22.8 MB of archives.After this operation, 109 MB of additional disk space will be used.Selecting previously unselected package docker-ce.(Reading database ... 120478 files and directories currently installed.)Preparing to unpack .../docker-ce_5%3a19.03.5~3-0~ubuntu-bionic_amd64.deb ...Unpacking docker-ce (5:19.03.5~3-0~ubuntu-bionic) ...Setting up docker-ce (5:19.03.5~3-0~ubuntu-bionic) ...Processing triggers for systemd (237-3ubuntu10.33) ...Processing triggers for ureadahead (0.100.0-21) ... It’s quite possible that the docker version that comes by default with your Linux distribution is not new enough. In that case you can add Docker’s own package repository and get a newer docker version from there:123456DOCKER_APT_REPO='https://download.docker.com/linux/ubuntu'curl -fsSL \"$&#123;DOCKER_APT_REPO&#125;/gpg\" | sudo apt-key add -OS=\"$(lsb_release -cs)\"sudo add-apt-repository \"deb [arch=amd64] $DOCKER_APT_REPO $OS stable\"sudo apt-get updatesudo apt-get -y -o Dpkg::Options::=\"--force-confnew\" install docker-ce Docker Experimental FeaturesAs of this writing (early 2020), buildx is an experimental feature. If you try to use it without turning on experimental features it’ll fail:123$ docker buildxdocker: 'buildx' is not a docker command.See 'docker --help' You can turn on experimental Docker CLI features in one of two ways. Either by setting an environment variable1$ export DOCKER_CLI_EXPERIMENTAL=enabled or by turning the feature on in the config file:$HOME/.docker/config.json1234&#123; ... \"experimental\" : \"enabled\"&#125;If you choose the environment variable, put the setting into you shell startup script, e.g. $HOME/.bashrc for bash, otherwise the setting only sticks around in your current shell until you log out. Once you have turned on experimental features either way, you can check that it has taken effect with:12345$ docker versionClient: Docker Engine - Community ... Experimental: true ... Note that this output also shows you the status of the Experimental flag of Server: Docker Engine. But this doesn’t concern us for now. With experimental mode now turned on, you should have access to the docker buildx command:123456789101112131415161718192021$ docker buildxUsage: docker buildx COMMANDBuild with BuildKitManagement Commands: imagetools Commands to work on images in registryCommands: bake Build from a file build Start a build create Create a new builder instance inspect Inspect current builder instance ls List builder instances rm Remove a builder instance stop Stop builder instance use Set the current builder instance version Show buildx version informationRun 'docker buildx COMMAND --help' for more information on a command. Linux KernelYou need a kernel that supports the binfmt_misc feature and has it enabled. In particular, the binfmt_misc support needed to use QEMU transparently inside containers is the fix-binary (F) flag which requires a Linux kernel version &gt;= 4.8 (commit, commit). You can check your kernel version with:12$ uname -r4.15.0 Binfmt_misc File SystemThe binfmt_misc kernel features are controlled via files in /proc/sys/fs/binfmt_misc/. This file system must be mounted. E.g. on an Ubuntu 18.04 (bionic) system the script responsible for mounting that file system is /lib/systemd/system/proc-sys-fs-binfmt_misc.automount which is part of the systemd package and runs automatically at boot time (and also during package installation). You can check if the file system is mounted with:12$ ls /proc/sys/fs/binfmt_misc/register status Host Installation: QEMUAn easy way to install statically linked QEMU binaries is to use a pre-built package for your host Linux distribution. E.g. for Debian or Ubuntu you can install it with:1234567891011121314151617181920212223242526$ sudo apt-get install -y qemu-user-staticReading package lists... DoneBuilding dependency treeReading state information... DoneThe following additional packages will be installed: binfmt-supportThe following NEW packages will be installed: binfmt-support qemu-user-static0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.Need to get 10.1 MB of archives.After this operation, 101 MB of additional disk space will be used.Get:1 http://us-east-2.ec2.archive.ubuntu.com/ubuntu bionic/main amd64 binfmt-support amd64 2.1.8-2 [51.6 kB]Get:2 http://us-east-2.ec2.archive.ubuntu.com/ubuntu bionic-updates/universe amd64 qemu-user-static amd64 1:2.11+dfsg-1ubuntu7.21 [10.0 MB]Fetched 10.1 MB in 0s (22.0 MB/s)Selecting previously unselected package binfmt-support.(Reading database ... 120409 files and directories currently installed.)Preparing to unpack .../binfmt-support_2.1.8-2_amd64.deb ...Unpacking binfmt-support (2.1.8-2) ...Selecting previously unselected package qemu-user-static.Preparing to unpack .../qemu-user-static_1%3a2.11+dfsg-1ubuntu7.21_amd64.deb ...Unpacking qemu-user-static (1:2.11+dfsg-1ubuntu7.21) ...Setting up binfmt-support (2.1.8-2) ...Setting up qemu-user-static (1:2.11+dfsg-1ubuntu7.21) ...Processing triggers for ureadahead (0.100.0-21) ...Processing triggers for systemd (237-3ubuntu10.33) ...Processing triggers for man-db (2.8.3-2ubuntu0.1) ... That has installed QEMU for a number of foreign architectures, e.g. 64-bit ARM (aarch64), as you can see by checking:12345$ ls -l /usr/bin/qemu-aarch64-static-rwxr-xr-x 1 root root 3621200 Oct 15 09:23 /usr/bin/qemu-aarch64-static$ qemu-aarch64-static --versionqemu-aarch64 version 2.11.1(Debian 1:2.11+dfsg-1ubuntu7.21)Copyright (c) 2003-2017 Fabrice Bellard and the QEMU Project developers Other Linux distributions might use different package managers or package names for the QEMU package. Alternatively you can install QEMU from source and follow the build instructions. Host Installation: update-binfmts ToolThe update-binfmts tool is typically part of the binfmt-support package. If you look back at the installation of qemu-user-static above you’ll see that it has automatically pulled in the recommended binfmt-support package, so in our case it’s already installed. But if you’ve specified the --no-install-recommends flag (or that is set by default on your system), binfmt-support might not yet been installed. If it’s missing on your system you can also install it manually with:1234567$ sudo apt-get install -y binfmt-supportReading package lists... DoneBuilding dependency treeReading state information... Donebinfmt-support is already the newest version (2.1.8-2).binfmt-support set to manually installed.0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded. Here again, we need support for the fix-binary (F) flag, which was added to update-binfmts with version 2.1.7. You can check the version with:12$ update-binfmts --versionbinfmt-support 2.1.8 Checking Your Host SystemPutting everything together, you can check if the afore mentioned environment is in place for using QEMU with docker buildx with the following script:check-qemu-binfmt.sh1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#!/bin/bash# (c) Artur.Klauser@computer.orgfunction error() &#123; echo \"ERROR: $*\" exit 1&#125;function ok() &#123; echo \"OK: $*\"&#125;function version() &#123; echo \"$(printf '%02d' $(echo $1 | tr . ' ' | sed -e 's/ 0*/ /g') 2&gt;/dev/null)\"&#125;function check_qemu_binfmt() &#123; # Docker if ! command -v docker &gt;/dev/null 2&gt;&amp;1; then error \"Can't find docker.\" \\ \"Install with 'sudo apt-get install docker-ce' or docker.io.\" fi docker_version=\"$(docker --version | cut -d' ' -f3 | tr -cd '[0-9.]')\" if [[ \"$(version $docker_version)\" &lt; \"$(version '19.03')\" ]]; then error \"docker $docker_version too old. Need &gt;= 19.03\" fi docker_experimental=\"$(docker version | \\ awk '/^ *Experimental:/ &#123;print $2 ; exit&#125;')\" if [[ \"$docker_experimental\" != 'true' ]]; then error \"docker experimental flag not enabled:\"\\ \"Set with 'export DOCKER_CLI_EXPERIMENTAL=enabled'\" else ok \"docker $docker_version supports buildx experimental feature.\" fi # Kernel kernel_version=\"$(uname -r)\" if [[ \"$(version $kernel_version)\" &lt; \"$(version '4.8')\" ]]; then error \"Kernel $kernel_version too old - need &gt;= 4.8.\" \\ \" Install a newer kernel.\" else ok \"kernel $kernel_version has binfmt_misc fix-binary (F) support.\" fi # binfmt_misc file system if [[ \"$(mount | grep -c '/proc/sys/fs/binfmt_misc')\" == '0' ]]; then error '/proc/sys/fs/binfmt_misc not mounted. Mount with' \\ \"'sudo mount -t binfmt_misc binfmt_misc /proc/sys/fs/binfmt_misc'\" else ok \"/proc/sys/fs/binfmt_misc is mounted\" fi # binfmt-support if ! command -v update-binfmts &gt;/dev/null 2&gt;&amp;1; then error \"Can't find update-binfmts.\" \\ \"Install with 'sudo apt-get install binfmt-support'.\" fi binfmt_version=\"$(update-binfmts --version | awk '&#123;print $NF&#125;')\" if [[ \"$(version $binfmt_version)\" &lt; \"$(version '2.1.7')\" ]]; then error \"update-binfmts $binfmt_version too old. Need &gt;= 2.1.7\" else ok \"update-binfmts $binfmt_version has fix-binary (F) support.\" fi # QEMU if [[ ! -e '/proc/sys/fs/binfmt_misc/qemu-aarch64' ]]; then # Skip this test if QEMU isn't registerd with binfmt_misc. It might come # from a docker image rather than the host file system. if [[ ! -e '/usr/bin/qemu-aarch64-static' ]]; then error \"Missing QEMU.\" \\ \" Install with 'sudo apt-get install qemu-user-static'.\" else ok \"QEMU installed\" fi fi if [[ ! -e '/proc/sys/fs/binfmt_misc/qemu-aarch64' ]]; then error 'QEMU not registed in binfmt_misc.' fi flags=\"$(cat /proc/sys/fs/binfmt_misc/qemu-aarch64 | \\ grep 'flags:' | cut -d' ' -f2)\" if [[ \"$(echo $flags | grep -c F)\" == '0' ]]; then error 'QEMU not registered in binfmt_misc with fix-binary (F) flag.' else ok \"QEMU registered in binfmt_misc with flags $flags (F is requried).\" fi echo \"Host looks good for docker buildx multi-architecture support\".&#125;set -echeck_qemu_binfmt \"$@\" Problem: QEMU Not Registered With (F) FlagIn some environments you can run into the situation that the appropriate kernel update-binfmts support is present, but the qemu-user-static post-install script does not register QEMU with the fix-binary (F) flag. The checker script above will point that out. One such environment is e.g. AWS EC2 instances running Ubuntu 18.04 (bionic). In such a case you can fix up the installation by re-registering QEMU with the fix-binary (F) flag with the following script:reregister-qemu-binfmt.sh1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/bash# (c) Artur.Klauser@computer.orgfunction remove_binfmt() &#123; local arch=\"$1\"; shift local package=\"$1\"; shift update-binfmts \\ --package \"$&#123;package&#125;\" \\ --remove \"qemu-$&#123;arch&#125;\" \"/usr/bin/qemu-$&#123;arch&#125;-static\"&#125;function install_binfmt() &#123; local arch=\"$1\"; shift local package=\"$1\"; shift local interpreter=\"$1\"; shift local offset=\"$1\"; shift local magic=\"$1\"; shift local mask=\"$1\"; shift update-binfmts \\ --package \"$&#123;package&#125;\" \\ --install \"qemu-$&#123;arch&#125;\" \"$&#123;interpreter&#125;\" \\ --offset \"$&#123;offset&#125;\" \\ --magic \"$&#123;magic&#125;\" \\ --mask \"$&#123;mask&#125;\" \\ --credentials yes \\ --fix-binary yes&#125;function reregister_qemu_binfmt() &#123; # Reregister all qemu interpreters with fix-binary flag which makes them # available inside containers and chroots, e.g. docker buildx works for # architectures supported by qemu interpreters. for file in /proc/sys/fs/binfmt_misc/qemu-*; do arch=\"$&#123;file/*qemu-/&#125;\" package=\"$(head -1 \"/var/lib/binfmts/qemu-$&#123;arch&#125;\")\" # Pull arguments from current registration. eval $(awk ' \\ /^(interpreter|offset|magic|mask)/ &#123;printf \"%s=\\\"%s\\\"\\n\",$1,$2&#125;' \\ \"$&#123;file&#125;\") # Convert to binary strings. magic=\"$(echo $magic | sed 's/\\(..\\)/\\\\x\\1/g')\" mask=\"$(echo $mask | sed 's/\\(..\\)/\\\\x\\1/g')\" echo \"Reregistering arch $arch\" remove_binfmt \"$&#123;arch&#125;\" \"$&#123;package&#125;\" install_binfmt \"$&#123;arch&#125;\" \"$&#123;package&#125;\" \"$&#123;interpreter&#125;\" \"$&#123;offset&#125;\" \"$&#123;magic&#125;+++\" \"$&#123;mask&#125;\" done&#125;set -ereregister_qemu_binfmt \"$@\" Docker Image Based InstallationAs an alternative to installing the QEMU and binfmt-support packages on your host system you can use a docker image to satisfy the corresponding requirements. There are several docker images that do the job, among them multiarch/qemu-user-static and docker/binfmt. They come loaded with QEMU simulators for several architectures and their own setup script for installing those QEMU simulators in the host kernel’s binfmt_misc with the fix-binary (F) flag. The QEMU simulators stay registered and usable by the host kernel after running those docker images as long as the host system remains up (or you explicitly unregister them from binfmt_misc). That is what also makes them usable by later runs of docker buildx. Unlike the host installation of packages though, you’ll need to re-run those docker images after every system reboot. Using those images doesn’t release you from having the right docker and kernel version on the host system, but you do get around installing QEMU and binfmt-support packages on the host. I like to use multiarch/qemu-user-static:1234567891011121314$ docker run --rm --privileged multiarch/qemu-user-static --reset -p yesUnable to find image 'multiarch/qemu-user-static:latest' locallylatest: Pulling from multiarch/qemu-user-staticbdbbaa22dec6: Pull complete42399a41a764: Pull completeed8a5179ae11: Pull complete1ec39da9c97d: Pull completedf7dd9470aac: Pull completeDigest: sha256:25d6e8bb037094525cd70da43edc06a62122028cb9ad434605affbd4fffb3a4fStatus: Downloaded newer image for multiarch/qemu-user-static:latestSetting /usr/bin/qemu-alpha-static as binfmt interpreter for alphaSetting /usr/bin/qemu-arm-static as binfmt interpreter for armSetting /usr/bin/qemu-armeb-static as binfmt interpreter for armeb... Status of Popular Linux EnvironmentsThe following table shows the current status of docker buildx support on various popular Linux environments. Only Ubuntu &gt;= 19.04 (disco) and Debian 11 (bullseye/testing) come with sufficient support by default to be able to run docker buildx out of the box. All older versions of these Linux distributions need updates of various components in order to be compatible with docker buildx usage. For example Ubuntu 18.04 (bionic) requires re-registration of QEMU with the fix-binary (F) flag or usage of the docker image installation method for QEMU as described above. Environment docker package Kernel binfmt-support (F) flag Requirements &gt;= 19.03 &gt;= 4.8 &gt;= 2.1.7 yes Ubuntu: 18.04 (bionic) 17.12.1 docker.io 4.15.0 2.1.8 no 19.04 (disco) 18.09.5 docker.io 5.0 2.2.0 yes 19.10 (eoan) 19.03.2 docker.io 5.3 2.2.0 yes 20.04 (focal) 19.03.2 docker.io 5.5 2.2.0 yes Debian: 9 (stretch) - 4.9.0 2.1.6 no 10 (buster) 18.09.1 docker.io 4.19.0 2.2.0 yes 11 (bullseye/testing) 19.03.4 docker.io 5.4 2.2.0 yes AWS EC2: Ubuntu 16.04 (xenial) 18.09.7 docker.io 4.4.0 2.1.6 no Ubuntu 18.04 (bionic) 18.09.7 docker.io 4.15.0 2.1.8 no Travis (on GCP): Ubuntu 14.04 (trusty) 17.09.0 docker-ce 4.4.0 2.1.4 no Ubuntu 16.04 (xenial) 18.06.0 docker-ce 4.15.0 2.1.6 no Ubuntu 18.04 (bionic) 18.06.0 docker-ce 4.15.0 2.1.8 no Github Actions (on Azure): Ubuntu 16.04 (xenial) 3.0.8 moby-engine 4.15.0 2.1.6 no Ubuntu 18.04 (bionic) 3.0.8 moby-engine 5.0.0 2.1.8 no Building Multi-Architecture Docker Images With BuildxWith all the software requirements on the host met, it’s time to turn our attention to how buildx is used to create multi-architecture docker images. The first step is setting up a buildx builder. Creating a Buildx BuilderThe docker CLI now understands the buildx command, but you also need to create a new builder instance which buildx can use:123$ docker buildx create --name mybuildermybuilder$ docker buildx use mybuilder You can check your newly created mybuilder with:1234567891011121314$ docker buildx inspect --bootstrap[+] Building 3.5s (1/1) FINISHED =&gt; [internal] booting buildkit 3.5s =&gt; =&gt; pulling image moby/buildkit:buildx-stable-1 2.9s =&gt; =&gt; creating container buildx_buildkit_mybuilder0 0.6sName: mybuilderDriver: docker-containerNodes:Name: mybuilder0Endpoint: unix:///var/run/docker.sockStatus: runningPlatforms: linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x,linux/386, linux/arm/v7, linux/arm/v6 Note how the Platforms line reports support for various non-native architectures which you have installed via QEMU. If it only reports support for linux/amd64 and linux/386 you either still haven’t met all software requirements, or you had created a builder before you have met the software requirements. In the latter case remove it with docker buildx rm and recreate it. You can also see your just created mybuilder with buildx’ ls subcommand:123456$ docker buildx lsNAME/NODE DRIVER/ENDPOINT STATUS PLATFORMSmybuilder * docker-container mybuilder0 unix:///var/run/docker.sock running linux/amd64, linux/arm64, linux/riscv64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6default docker default default running linux/amd64, linux/arm64, linux/ppc64le, linux/s390x, linux/386, linux/arm/v7, linux/arm/v6 Using Buildx to BuildAlright, now we’re ready to build multi-architecture docker images with buildx. To have something concrete to work with we’re going to use the following example:Dockerfile12FROM alpine:latestCMD echo \"Running on $(uname -m)\" It’s a simple stand-in for whatever you’d like to build yourself in your own Dockerfile. It uses the latest Alpine distribution - which itself is a multi-architecture docker image - and issues a command to print out the architecture on which it is executing. That will allow us to check which kind of image we’re running. The docker buildx build subcommand has a number of flags which determine where the final image will be stored. By default, i.e. if none of the flags are specified, the resulting image will remain captive in docker’s internal build cache. This is unlike the regular docker build command which will store the resulting image in the local docker images list. The important flags are: --load: This flag instructs docker to load the resulting image into the local docker images list. However, this currently only works for single-architecture images. If you try this with multi-architecture images you’ll get an export error:$ docker buildx build ... --load ...... =&gt; ERROR exporting to oci image format 0.0s------ &gt; exporting to oci image format:------failed to solve: rpc error: code = Unknown desc = docker exporter does not currently support exporting manifest lists --push: This flag tells docker to push the resulting image to a docker registry. Your image tag has to contain the proper reference to the registry and repository name. This currently is the best way to store multi-architecture images. We’re going to use the default Docker Hub registry. First we have to log in:12345678$ export DOCKER_USER='arturklauser'$ docker login -u \"$DOCKER_USER\"Password: *****WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded Now we can build and use the --push flag to push the image to Docker Hub. We’re going to build for three different architectures which are specified with the --platform flag:123456789101112131415161718192021222324252627$ docker buildx build -t \"$&#123;DOCKER_USER&#125;/buildx-test:latest\" \\ --platform linux/amd64,linux/arm64,linux/ppc64le --push .[+] Building 1.5s (9/9) FINISHED =&gt; [internal] load build definition from Dockerfile 0.0s =&gt; =&gt; transferring dockerfile: 91B 0.0s =&gt; [internal] load .dockerignore 0.0s =&gt; =&gt; transferring context: 2B 0.0s =&gt; [linux/ppc64le internal] load metadata for docker.io/library/alpine:l 0.1s =&gt; [linux/amd64 internal] load metadata for docker.io/library/alpine:lat 0.2s =&gt; [linux/arm64 internal] load metadata for docker.io/library/alpine:lat 0.2s =&gt; CACHED [linux/ppc64le 1/1] FROM docker.io/library/alpine:latest@sha25 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679240 0.0s =&gt; CACHED [linux/amd64 1/1] FROM docker.io/library/alpine:latest@sha256: 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679240 0.0s =&gt; CACHED [linux/arm64 1/1] FROM docker.io/library/alpine:latest@sha256: 0.0s =&gt; =&gt; resolve docker.io/library/alpine:latest@sha256:2171658620155679240 0.0s =&gt; exporting to image 1.2s =&gt; =&gt; exporting layers 0.0s =&gt; =&gt; exporting manifest sha256:cc57b693aba3acedeec2e624b55e543919173a3e 0.0s =&gt; =&gt; exporting config sha256:d90689831fec93dd68f90509031907cc262f89ec60 0.0s =&gt; =&gt; exporting manifest sha256:7997da18dbf6e4b2748736821ec6f1dd11d6e849 0.0s =&gt; =&gt; exporting config sha256:c105b7a88a6002ad96802aa287be3872d86608abfb 0.0s =&gt; =&gt; exporting manifest sha256:6ed2267dc7082fbfc4454805b94326418ad14c53 0.0s =&gt; =&gt; exporting config sha256:5df18a6f10cc8591839d1b29732d3d202edf3c0f4e 0.0s =&gt; =&gt; exporting manifest list sha256:57ca2d778839da0b6287bcbc99fc2299b0c 0.0s =&gt; =&gt; pushing layers 0.2s =&gt; =&gt; pushing manifest for docker.io/arturklauser/buildx-test:latest 0.7s Checking the image on the Docker Hub web site we see it reported as:DIGEST OS/ARCH COMPRESSED SIZEcc57b693aba3 linux/amd64 2.67 MB7997da18dbf6 linux/arm64 2.59 MB6ed2267dc708 linux/ppc64le 2.69 MB To verify that you’ve actually got what you’ve been promised, let’s try to run the image:123456$ docker run --rm \"$DOCKER_USER/buildx-test:latest\"Unable to find image 'arturklauser/buildx-test:latest' locallylatest: Pulling from arturklauser/buildx-testDigest: sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5Status: Downloaded newer image for arturklauser/buildx-test:latestRunning on x86_64 As expected, since we’re running on a 64-bit x86 host, the architecture version that was used by docker was the amd64 which reports running on x86_64. If you check the local image in docker it confirms that:12$ docker inspect --format \"&#123;&#123;.Architecture&#125;&#125;\" \"$DOCKER_USER/buildx-test:latest\"amd64 In order to be able to try non-native image versions we need to turn on another experimental feature, this time in the docker engine, that’ll allow us to specify a --platform when we pull and run images. If docker engine experimental features are not turned on you’ll get an error instead: “–platform” is only supported on a Docker daemon with experimental features enabled Change the docker engine configuration file or create it if it doesn’t exist already:/etc/docker/daemon.json1234&#123; ... \"experimental\" : true&#125;After changing the configuration file you’ll also need to restart dockerd for the change to take effect:1$ sudo systemctl restart docker Now let’s purge the image that we’ve already pulled and try a different architecture:1234567891011$ docker rmi \"$DOCKER_USER/buildx-test:latest\"Untagged: arturklauser/buildx-test:latestUntagged: arturklauser/buildx-test@sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5$ docker run --rm --platform linux/aarch64 \"$DOCKER_USER/buildx-test:latest\"Unable to find image 'arturklauser/buildx-test:latest' locallylatest: Pulling from arturklauser/buildx-testcde5963f3b93: Pull complete Digest: sha256:57ca2d778839da0b6287bcbc99fc2299b0cea29e5fe4cff8492a1ba6e62fc8c5Status: Downloaded newer image for arturklauser/buildx-test:latestRunning on aarch64 And now we can see that the architecture version of the image we’ve pulled and run is the one for 64-bit ARM aarch64, as can also be verified by looking at the image metadata:12$ docker inspect --format \"&#123;&#123;.Architecture&#125;&#125;\" \"$DOCKER_USER/buildx-test:latest\"arm64 And with this you’ve got to the point where you can start to build your own multi-architecture docker images with buildx. Happy developing!","categories":[],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://nexus.eddiesinentropy.net/tags/Docker/"}],"author":"Artur Klauser"},{"title":"Mounting Google Drive on Raspberry Pi","slug":"Mounting-Google-Drive-on-Raspberry-Pi","date":"2019-04-21T16:22:00.000Z","updated":"2019-05-21T10:43:45.000Z","comments":true,"path":"2019/04/21/Mounting-Google-Drive-on-Raspberry-Pi/","link":"","permalink":"https://nexus.eddiesinentropy.net/2019/04/21/Mounting-Google-Drive-on-Raspberry-Pi/","excerpt":"How to use rclone, FUSE, and systemd to automatically mount your Google Drive on your Raspberry Pi.","text":"How to use rclone, FUSE, and systemd to automatically mount your Google Drive on your Raspberry Pi. The Raspberry Pi is a great little device to run a variety of services in your home network. It saves files on a user-provided SD card or USB stick. But what if you want to store files off-device to safeguard the work that you’ve put in to set up whatever services you’re running on your Pi? What if you would like to share files between multiple Pis? Or what if you have files like your photos living in the cloud already and you’d like to easily access them from your Pi? This article shows how you can connect your Google Drive to your Raspberry Pi for all the above use cases and more. Which Software to Use?The first thing we have to decide is which software to use. When you look around for software to connect Google Drive to a Linux environment you run into projects with a wide range of different features and requirements. Some are better maintained than others. The one I’ve chosen here is rclone, which is actively maintained and provides a lot of functionality. In particular, with the help of the FUSE userspace filesystem layer, it allows you to mount Google Drive as part of your Linux file system, which greatly simplifies using the cloud storage from your Pi. These instructions will probably also work on most other Debian Linux based distributions with little or no change. Rclone is much more versatile that the limited usage described in this article. It doesn’t only support Google Drive but a whole host of other cloud storage providers as well, such as Amazon Drive, Dropbox, or Microsoft OneDrive to name just a few of the larger ones. Besides allowing you to mount one of those cloud storage services into your file system, it also provides a set of CLI commands to directly manipulate files on those services. In this article, however, we won’t use them and concentrate on using rclone mount. The installation instructions below assume that you’re logged in to your Raspberry Pi and execute all instructions there, unless otherwise noted. Installing Rclone on RaspbianThe easiest way to install rclone is to use the pre-compiled Debian package:1sudo apt-get install rclone As of this writing, the current release of Raspbian is based on Debian v.9 (Stretch), and the version of rclone we get via apt-get is 1.35. However, rclone has progressed to version 1.47 in the meantime. To get a more up-to-date version, instead of using the apt package that comes with the default Raspbian package repositories, we’re going to install an up-to-date rclone package from its download page:1234cd /tmpwget https://downloads.rclone.org/v1.47.0/rclone-v1.47.0-linux-arm.debsudo apt install ./rclone-v1.47.0-linux-arm.debrm rclone-v1.47.0-linux-arm.deb Configuring RcloneSince the remote files we’re going to access are private to a particular user, rclone keeps configuration files separate per user. All secret access tokens necessary to interact with the cloud storage are stored in a user’s config file such that different users can’t access each other’s cloud storage. By default the config file is located in $HOME/.config/rclone/rclone.conf and should have permissions of 0600 (read-write only for file owner) to make sure your access tokens remain private. For Google Drive there is another consideration. If you go with the default configuration, you’re using the client_id that corresponds to the rclone application. Google imposes per-client rate limits on interactions with Google Drive. This means that by using the rclone default client_id you’re competing against all other users of rclone, globally, for operation bandwidth to Google Drive. Even though the rclone authors try to mitigate this by asking Google for higher quotas, using the default is not an ideal situation. For this reason we’ll set up our own client_id with Google and avoid the stampede. Getting a Google Drive Client IDIn a browser go to the Google Developer Console and log in with your Google account. You don’t have to do this on your Raspberry Pi. Any computer is fine. On the top go to Select a project → New Project Fill in a Project Name: my-rclone-gdrive-access Hit Create Just below the top select + ENABLE APIS AND SERVICES Search for Drive Select Google Drive API Hit Enable On the left side-panel select Credentials In the main panel you’ll get a warning about Remember to configure the OAuth consent screen with information about your application. Next to the warning select CONFIGURE CONSENT SCREEN Fill in the Application Name: my-rclone Hit Add Scope Pick ../auth/drive (which can “see, edit, create, and delete all of your Google Drive files”) and hit Add Hit Save Go back to Credentials on the left side-panel and then Credentials on the top menu inside the main panel Select Create credentials → OAuth client ID Select Application type: Other and set some sensible name: my rclone client Hit Create You’ll get a confirmation page containing the client ID and client secret which looks like this. Copy the client ID and client secret since we’ll need it for the rclone configuration. Setting up the Rclone ConfigurationBack on the Raspberry Pi log in as the user who should be able to access the Google Drive files and run:1rclone config Select the following answers: No remotes found - make a new one n) New remote s) Set configuration password q) Quit config n/s/q> n name> gdrive Type of storage to configure. Enter a string value. Press Enter for the default (\"\"). Choose a number from below, or type in your own value ... snip ... 12 / Google Drive \\ \"drive\" ... snip ... Storage> 12 See help for drive backend at https://rclone.org/drive/ Google Application Client Id Setting your own is recommended. See https://rclone.org/drive/#making-your-own-client-id for how to create your own. If you leave this blank, it will use an internal key which is low performance. Enter a string value. Press Enter for the default (\"\"). client_id> 425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com This is the client ID that you saved in the previous step. Google Application Client Secret Setting your own is recommended. Enter a string value. Press Enter for the default (\"\"). client_secret> MspFTowlsy0SUSRm-1RvcTyx This is the client secret that you saved in the previous step. Scope that rclone should use when requesting access from drive. Enter a string value. Press Enter for the default (\"\"). Choose a number from below, or type in your own value 1 / Full access all files, excluding Application Data Folder. \\ \"drive\" ... snip ... scope> 1 ID of the root folder Leave blank normally. Fill in to access \"Computers\" folders. (see docs). Enter a string value. Press Enter for the default (\"\"). root_folder_id> Service Account Credentials JSON file path Leave blank normally. Needed only if you want use SA instead of interactive login. Enter a string value. Press Enter for the default (\"\"). service_account_file> Edit advanced config? (y/n) y) Yes n) No y/n> n Remote config Use auto config? * Say Y if not sure * Say N if you are working on a remote or headless machine y) Yes n) No y/n> n If your browser doesn't open automatically go to the following link: https://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=18109698827ea077947354ca9dab0b80 Log in and authorize rclone for access Copy the URL that gets printed on your screen to a new browser window. You can do this on any computer, it doesn’t have to be your Pi. In the page flow that follows select your user account (if required) and confirm that you want to give your application access to your Google Drive. Copy the verification code from the confirmation page and fill it in below. Enter verification code> 4/PzWg7ZOEvXIoa9tI7OMjerPq_X5UpsES5ayNvtG8Gf9TK30FERTVrCM Configure this as a team drive? y) Yes n) No y/n> n -------------------- [gdrive] type = drive client_id = 425159802070-tup27t8cv4h2z3cjkqfmft4n8gju76lf.apps.googleusercontent.com client_secret = MspFTowlsy0SUSRm-1RvcTyx scope = drive token = {\"access_token\":\"xa14.Gv7qcPS5TvrumTpNplGxg5Ndct1gd6yica0d80iFjbKXJ3KpgneZLvn-Tg-YgLPXcEesHubbBcyyeEjGGb9mP5GhwLnEDxaPhPS3fj6ddTcmMUUOdjOhYW-rb1xY\",\"token_type\":\"Bearer\",\"refresh_token\":\"1/8jxfWbRseQmqrb5aebwK9zfwZRH0IjZhv-9lmtqsVC8\", \"expiry\":\"2020-01-23T16:21:03.502362868-07:00\"} -------------------- This last section shown above is a copy of the information that will be put into the $HOME/.config/rclone/rclone.conf config file. If everything looks correct we’re going to accept it and exit the configuration menu. y) Yes this is OK e) Edit this remote d) Delete this remote y/e/d> y Current remotes: Name Type ==== ==== gdrive drive e) Edit existing remote n) New remote d) Delete remote r) Rename remote c) Copy remote s) Set configuration password q) Quit config e/n/d/r/c/s/q> q You can now test that you have set up the configuration correctly with:1rclone ls --max-depth 1 gdrive: This rclone command should show you all regular files in the top-level directory of your Google Drive. The next step is to test mounting Google Drive into your file system:123cd ~mkdir -p mnt/gdriverclone mount gdrive: $HOME/mnt/gdrive In a second terminal on your Raspberry Pi run:1ls -l ~/mnt/gdrive This should again list all files in the top-level directory of your Google Drive. Since your cloud storage is now part of the regular file system, any program on you Pi can access it just like any other file. After this test stop the above rclone command in the first terminal with Ctrl-C. Automatically Mounting Google DriveThe setup above is all that is necessary to use the rclone mount command and mount Google Drive by hand into your file system whenever you need it. However, that is a bit cumbersome. It would be better if Google drive were mounted automatically whenever the corresponding user logs in. This can be achieved with systemd, a daemon that starts and stops services when needed. Systemd operates in one of two modes, a –system mode that handles machine-wide services such as bringing up networking, and a –user mode that deals with per-user services such as starting the desktop environment and in our case we want it to mount the rclone FUSE file system for Google Drive. A good place to learn more is the archlinux wiki for per-user systemd. Configuring SystemdTo tell systemd what to do it depends on configuration files in some standard locations. One of these locations where systemd looks for user config files is $HOME/.config/systemd/user. To have the rclone FUSE file system mounted automatically at login we’ll create a ~/.config/systemd/user/rclone@.service file with the following contents:12345678910111213141516[Unit]Description=rclone: Remote FUSE filesystem for cloud storage config %iDocumentation=man:rclone(1)[Service]Type=notifyExecStartPre=/bin/mkdir -p %h/mnt/%iExecStart= \\ /usr/bin/rclone mount \\ --fast-list \\ --vfs-cache-mode writes \\ --vfs-cache-max-size 100M \\ %i: %h/mnt/%i[Install]WantedBy=default.target Here the special @ syntax in the config filename defines a service template which allows to write a single config file that can be used for multiple instantiations. Even though we wouldn’t really need a service template for our simple use case, we use it so the configuration already supports multiple mounts, e.g. if you also want to use it for other cloud storage providers as well. When using the systemd service name, which derives from the file name, you just append an instance name to @ and systemd will replace all occurrences of %i in the config file with that instance name. In our case the instance name represents the rclone remote name which we have configured in the rclone.conf file above, i.e. gdrive in our case. On the rclone mount command line above we use a particular set of mount options that are supported for Google Drive. A full list of options can be found in the rclone Google Drive documentation. More details on general mount options can be found in the rclone mount documentation. Once we’ve got the config file in place we need to let systemd know about the new configuration for our gdrive rclone remote:1systemctl --user enable rclone@gdrive This should install a symbolic link rclone@gdrive.service -&gt; $HOME/.config/systemd/user/rclone@.service in ~/.config/systemd/user/default.target.wants/. Now that systemd is aware of the new service, the next step is to turn it on:1systemctl --user start rclone@gdrive Once turned on, when you list the mount directory1ls -l ~/mnt/gdrive you should see the contents of your Google Drive directory again. At this point what we have achieved works great for interactive user sessions. Every time you log in to your Raspberry Pi as the user for which you have set up Google Drive, it is mounted automatically into the file system which gives you access to the contents of your cloud storage. Starting User-Systemd at Boot TimeFor some use cases, mounting at user login time is still not quite enough. For example on my system I run an RStudio Server, which is a web IDE for the R programming language. The RStudio Server web interface first presents a login page to authenticate the user. Once it has checked the user’s credentials it starts an rsession for them. However, starting an rsession with the UID of the authenticated user doesn’t constitute a login or session for that user. Thus no systemd user session is started and the actions that would mount the cloud storage are not performed, so the RStudio IDE doesn’t have access to the cloud storage directory of the user. There is a solution to this problem though. We can instruct systemd to start a user session at boot time instead of login time with the following command:1loginctl enable-linger $USER Now, whenever our Raspberry Pi reboots, a systemd user session is started immediately for that user, mounting the configured Google Drive and enabling use cases like RStudio Server mentioned above. If you’ve followed the setup to here, congratulations! You’ve got your Raspberry Pi connected to your Google Drive and can easily access files from your cloud storage from any program running on your Pi just by accessing files under $HOME/mnt/gdrive.","categories":[],"tags":[{"name":"Raspberry Pi","slug":"Raspberry-Pi","permalink":"https://nexus.eddiesinentropy.net/tags/Raspberry-Pi/"}],"author":"Artur Klauser"}]}